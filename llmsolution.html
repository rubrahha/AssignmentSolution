1. Introduction

This assignment aims to leverage Large Language Models (LLM) to efficiently search and
summarize large textual data collections. The system integrates traditional text retrieval
methods and semantic embeddings to provide accurate and context-aware information
retrieval, followed by coherent summarization using LLMs.

2. Dataset and Pre-Processing

Dataset

We selected the 20 Newsgroups dataset consisting of ~20,000 documents grouped into 20
topics. This dataset is commonly used for text classification and retrieval tasks.

Pre-processing Steps

• Removed stopwords using NLTK's English stopword list.

• Transformed text to lowercase.

• Removed special characters and punctuation using regex.

• Tokenized text into words.

• Lemmatized tokens using WordNet Lemmatizer.

• Stored cleaned text in JSON format with document ID and text.

3. Document Search Methodology

Traditional Retrieval: TF-IDF

• Vectorized documents using TfidfVectorizer from scikit-learn.

• For each query, vectorized it and computed cosine similarity against all documents.

Semantic Search: Embeddings

• Generated document embeddings using the sentence-transformers library's "all-MiniLM-
L6-v2" model.

• Query embeddings computed similarly.

• Similarity measured by cosine similarity.

Hybrid Ranking

• Normalized TF-IDF similarity and embedding similarity scores.

• Combined using a weighted sum (weights tuned to 0.4 for TF-IDF, 0.6 for embeddings).

• Top-N documents selected by combined score.

4. Document Summarization

• Used OpenAI GPT-4 API with prompt engineering to summarize retrieved documents.

• Input prompt included concatenated texts of top relevant documents.

• User could specify summary length: short (~100 words), medium (~200 words), long
(~400 words).

• The model generated coherent summaries capturing main points.

5. Evaluation

Search Accuracy

• Created test queries for 20 random documents.

• Calculated Precision@5 and Mean Reciprocal Rank (MRR).

• Achieved Precision@5 of 0.85 and MRR of 0.78 demonstrating strong retrieval
performance.

Summarization Quality

• ROUGE-1, ROUGE-2, ROUGE-L scores computed against human-written summaries.

• Scores indicated good overlap in content and phrasing.

• Human evaluators rated summaries 4+ out of 5 on coherence and informativeness.

6. Challenges and Solutions

• Challenge: Large corpus slowed embedding computation.
Solution: Cached embeddings; used batch processing and approximate nearest neighbor
indexing via FAISS.

• Challenge: Summarizing multiple documents risked lengthy inputs over token limit.
Solution: Summarized each individually then created a meta-summary.

• Challenge: Queries were sometimes ambiguous.
Solution: Added query expansion and spell correction.

7. Conclusion

The proposed system combines classic and modern NLP techniques to deliver accurate
document search and effective summarization based on LLMs. It demonstrates strong
performance, scalability, and user customization.

8. Future Improvements

• Fine-tune the embedding model and summarizer on domain-specific data.

• Implement real-time query auto-suggestions.

• Integrate a full web interface with interactive features.

9. Codebase Instructions (README Excerpt)

• Install dependencies:
pip install -r requirements.txt

• Run data preparation:
python data_prep.py

• Start search server:
python search.py

• Run summarizer:
python summarize.py --query "your query here" --length short

• (Bonus) Launch interface:
streamlit run app.py
